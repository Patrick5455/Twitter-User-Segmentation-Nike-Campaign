{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Twitter Database using Tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API  \n",
    "from tweepy import Cursor\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from collections import Counter\n",
    "import os, sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load dotenv to expose api keys to the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_key API_secret_key Access_token Access_token_secret\n"
     ]
    }
   ],
   "source": [
    "API_key=\"API_key\"\n",
    "API_secret_key=\"API_secret_key\"\n",
    "Access_token=\"Access_token\"\n",
    "Access_token_secret=\"Access_token_secret\"\n",
    "print(API_key, API_secret_key, Access_token, Access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = os.environ.get(API_key)\n",
    "API_secret_key = os.environ.get(API_secret_key)\n",
    "Access_token = os.environ.get(Access_token)\n",
    "Access_token_secret=os.environ.get(Access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(API_key, API_secret_key)\n",
    "auth.set_access_token(Access_token, Access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "auth_api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Testing Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @chriscartw83: Again, after yesterday  , is #Antartica preparing a nasty surprise? \n",
      "\n",
      "Look at the latest trend\n",
      "\n",
      "#ClimateCrisis\n",
      "#climatech…\n",
      "RT @SirChar17262525: This year has seen unprecedented #wildfires cause havoc across the world. #Australia recently battled its largest #bus…\n"
     ]
    }
   ],
   "source": [
    "search_words = \"#wildfires\"\n",
    "date_since= \"2018-11-16\"  \n",
    "# Collect tweets\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "              q=search_words,\n",
    "              lang=\"en\", \n",
    "              since=date_since).items(2)\n",
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Define function to get tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(handles):\n",
    "    \n",
    "    cols = ['id', 'name', 'screen_name', 'description', \n",
    "            'statuses_count', 'friends_count', 'followers_count', \n",
    "            'account_age_days', 'avg_daily_tweets', 'hashtags',\n",
    "            'user_mentions','favorite_count', 'retweet_count',]\n",
    "    \n",
    "    # dataframe that would be returned at the end\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    #print(df)\n",
    "    handle_data = []\n",
    "    off_users = []\n",
    "            \n",
    "    if len(handles) > 0: \n",
    "        for handle in handles:\n",
    "            value_list = []\n",
    "            print(\"Getting data for \" + handle)\n",
    "            # this helps avoid Tweepy errors like suspended users or user not ound errors\n",
    "            try:\n",
    "                item = auth_api.get_user(handle)\n",
    "            except tweepy.TweepError as e:\n",
    "                continue\n",
    "            value_list+= item.id_str, item.name, item.screen_name,\\\n",
    "            item.description, item.statuses_count, item.friends_count, item.followers_count\n",
    "            \n",
    "            #get average daily tweets\n",
    "            \n",
    "            no_tweets = item.statuses_count\n",
    "            account_created_date = item.created_at\n",
    "            delta = datetime.utcnow() - account_created_date\n",
    "            account_age_days = delta.days\n",
    "            value_list.append(str(account_age_days))\n",
    "            #print(str(account_age_days))\n",
    "            if account_age_days > 0:\n",
    "                   value_list.append(int(float(no_tweets)/float(account_age_days)))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            hashtags = []\n",
    "            mentions = []\n",
    "            favorite_count =[]\n",
    "            retweet_count=[]\n",
    "            tweets = [] \n",
    "            tweet_count = 0\n",
    "            end_date = datetime.utcnow() - timedelta(days=30)\n",
    "            \n",
    "\n",
    "            for status in Cursor(auth_api.user_timeline, id=handle).items():\n",
    "                \n",
    "#                 tweets_list = [tweet.text for tweet in status] \n",
    "#                 for j in tweets_for_csv: \n",
    "#                     # Appending tweets to the empty array tmp \n",
    "#                     tweets.append(j)  \n",
    "                \n",
    "                tweets.append(status['text'])\n",
    "                tweet_count+= 1\n",
    "                if hasattr(status, \"entities\"):\n",
    "                    entities = status.entities\n",
    "\n",
    "                # get hashtags\n",
    "                if \"hashtags\" in entities:\n",
    "                    for ent in entities[\"hashtags\"]:\n",
    "                        if ent is not None:\n",
    "                            if \"text\" in ent:\n",
    "                                hashtag = ent[\"text\"]\n",
    "                                if hashtag is not None:\n",
    "                                    hashtags.append(hashtag)\n",
    "                # get usermentions\n",
    "                if \"user_mentions\" in entities:\n",
    "                    for ent in entities[\"user_mentions\"]:\n",
    "                        if ent is not None:\n",
    "                            if \"screen_name\" in ent:\n",
    "                                name = ent[\"screen_name\"]\n",
    "                                if name is not None:\n",
    "                                    mentions.append(name)\n",
    "\n",
    "                # get retweets    \n",
    "                if hasattr(status, \"retweet_count\"):\n",
    "                    retweets = status.retweet_count\n",
    "                    if retweets is not None:\n",
    "                        retweet_count.append(retweets)\n",
    "                        \n",
    "                # favorite count     \n",
    "                if hasattr(status, \"favorite_count\"):\n",
    "                    likes = status.favorite_count \n",
    "                    if likes is not None:\n",
    "                        favorite_count.append(likes)\n",
    "                if status.created_at < end_date:\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "            value_list.append(len(hashtags))\n",
    "            value_list.append(len(mentions))\n",
    "            value_list.append(sum(favorite_count))\n",
    "            value_list.append(sum(retweet_count))\n",
    "            handle_data.append(value_list)\n",
    "            #print(handle_data)\n",
    "            #break\n",
    "    #ls = {}\n",
    "            #df_1 = pd.DataFrame([handle_data], columns=cols)\n",
    "            #print(handle_data)\n",
    "            #complete_df = pd.concat(df, df_1)\n",
    "            tweet_series = pd.Series(tweets)\n",
    "            df = df.append(pd.DataFrame([value_list], columns=cols))\n",
    "            df=pd.concat([df, pd.DataFrame(tweet_series)], axis=1)\n",
    "            #print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Load scraped handles into pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "afriq_users_handle = pd.read_csv('scraped_handles/top_100_influencers.csv')\n",
    "afriq_users_handle = afriq_users_handle.handles.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@gettleman', '@a24media', '@andiMakinana', '@AfricaCheck']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afriq_users_handle[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@EswatiniGovern1', '@MalawiGovt', '@hagegeingob', '@FinanceSC']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afriq_govt_handle = pd.read_csv('scraped_handles/africa_govt_covid_resp.csv')\n",
    "afriq_govt_handle = afriq_govt_handle.handles.to_list()\n",
    "afriq_govt_handle[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Gather Twitter Data for Influencers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inf = get_tweets(afriq_users_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save Gathered Twitter Data of Top African Influencers to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inf.to_csv('twitter_datasets/acct_info/afriqTopInfluencers.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Gather Twitter Data for Governement Covid19 Responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for @EswatiniGovern1\n",
      "Getting data for @MalawiGovt\n",
      "Getting data for @hagegeingob\n",
      "Getting data for @FinanceSC\n",
      "Getting data for @PresidencyZA\n",
      "Getting data for @mohzambia\n",
      "Getting data for @edmnangagwa\n",
      "Getting data for @MinSantedj\n",
      "Getting data for @hawelti\n",
      "Getting data for @StateHouseKenya\n",
      "Getting data for @PaulKagame\n",
      "Getting data for @M_Farmaajo\n",
      "Getting data for @SouthSudanGov\n",
      "Getting data for @SudanPMHamdok\n",
      "Getting data for @TZSpokesperson\n",
      "Getting data for @KagutaMuseveni\n",
      "Getting data for @angola_Mirex\n",
      "Getting data for @willynyamitwe\n",
      "Getting data for @Cherif_MZ\n",
      "Getting data for @Presidence_RDC\n",
      "Getting data for @PresidentABO\n",
      "Getting data for @PresidenceBenin\n",
      "Getting data for @rochkaborepf\n",
      "Getting data for @PresidenciaCV\n",
      "Getting data for @AOuattara_PRCI\n",
      "Getting data for @Presidency_GMB\n",
      "Getting data for @NAkufoAddo\n",
      "Getting data for @President_GN\n",
      "Getting data for @USEmbalo\n",
      "Getting data for @PresidenceMali\n",
      "Getting data for @CheikhGhazouani\n",
      "Getting data for @IssoufouMhm\n",
      "Getting data for @MBuhari\n",
      "Getting data for @Macky_Sall\n",
      "Getting data for @PresidentBio\n",
      "Getting data for @MSPS_Togo\n",
      "Getting data for @TsholetsaDomi\n",
      "Getting data for @Azali_officiel\n",
      "Getting data for @SE_Rajoelina\n",
      "Getting data for @PKJugnauth\n",
      "Getting data for @AbiyAhmedAli\n",
      "Getting data for @PR_Paul_BIYA\n",
      "Getting data for @MinistereComCG\n"
     ]
    }
   ],
   "source": [
    "df_gov = get_tweets(afriq_govt_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save gathered data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gov.to_csv('twitter_datasets/acct_info/afriqGovCovid19Resp.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Define function to gather hashtags of handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags(handles):\n",
    "#    import timeit as t\n",
    "\n",
    "    \n",
    "    cols = ['id', 'name', 'screen_name', 'hashtags']#'hashtag_counts']\n",
    "    \n",
    "    # dataframe that would be returned at the end\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    #print(df)\n",
    "    handle_data = []\n",
    "            \n",
    "    if len(handles) > 0: \n",
    "        for handle in handles:\n",
    "            value_list = {}\n",
    "            print(\"Getting hashtags for \" + handle)\n",
    "            # this helps avoid Tweepy errors like suspended users or user not ound errors\n",
    "            try:\n",
    "                item = auth_api.get_user(handle)\n",
    "            except tweepy.TweepError as e:\n",
    "                continue\n",
    "            #value_list+= item.id_str, item.name, item.screen_name,\n",
    "            value_list['id'] = item.id_str\n",
    "            value_list['name'] = item.name\n",
    "            value_list['screen_name'] = item.screen_name\n",
    "            #value_list['hashtags'] = []\n",
    "            #print(value_list, \"hell\")\n",
    "            \n",
    "            #get average daily tweets\n",
    "            no_tweets = item.statuses_count\n",
    "            account_created_date = item.created_at\n",
    "            delta = datetime.utcnow() - account_created_date\n",
    "            account_age_days = delta.days\n",
    "           \n",
    "            hashtags = set()\n",
    "            hash_dic = {}\n",
    "            tweet_count = 0\n",
    "            end_date = datetime.utcnow() - timedelta(days=30)\n",
    "            \n",
    "\n",
    "            for status in Cursor(auth_api.user_timeline, id=handle).items():\n",
    "            #    tweet_count+= 1\n",
    "                if hasattr(status, \"entities\"):\n",
    "                    entities = status.entities\n",
    "\n",
    "                # get hashtags\n",
    "                if \"hashtags\" in entities:\n",
    "                    for ent in entities[\"hashtags\"]:\n",
    "                        if ent is not None:\n",
    "                            if \"text\" in ent:\n",
    "                                hashtag = ent[\"text\"]\n",
    "                                if hashtag is not None:\n",
    "                                    #print(hashtag)\n",
    "                                    if hashtag in hashtags:\n",
    "                                        hash_dic[hashtag]+=1\n",
    "                                    else:\n",
    "                                        hashtags.add(hashtag)\n",
    "                                        hash_dic[hashtag] = 1\n",
    "                value_list['hashtags'] = hash_dic\n",
    "            try:\n",
    "                #escape handles with no hashtags\n",
    "                df = df.append(pd.DataFrame(value_list))\n",
    "                # the code snippet below before the return is used to save to file due to constant connections loss\n",
    "                new_df = df.reset_index().rename(columns={'hashtags':'hashtags_count','index':'hashtags'})\n",
    "                new_df.to_csv('twitter_datasets/acct_hashtags/afriqInfHashtags3.csv')\n",
    "            except Error as e:\n",
    "                continue\n",
    "    return df.reset_index().rename(columns={'hashtags':'hashtags_count','index':'hashtags'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Gather hashtags of govt covid19 responders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gov_hashtags = get_hashtags(afriq_govt_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gov_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gov_hashtags.to_csv('twitter_datasets/acct_hashtags/govtHashtags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afriq_users_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Gather hashtags of Africa Influencers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First Half downlaod in _twitter_datasets/acct_hashtags/afriqInfHashtags.csv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inf_hashtags = get_hashtags(afriq_users_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inf_hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Seconf Half download in _twitter_datasets/acct_hashtags/afriqInfHashtags2.csv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afriq_users_handle.index('@africaprogress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(afriq_users_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "afriq_users_handle2 = afriq_users_handle[62:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inf_hashtags2 = get_hashtags(afriq_users_handle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Third part download in _twitter_datasets/acct_hashtags/afriqInfHashtags2.csv_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afriq_users_handle.index('@africaprogress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(afriq_users_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "afriq_users_handle2 = afriq_users_handle[62:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inf_hashtags2 = get_hashtags(afriq_users_handle2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Data for users' all Tweets Reply count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['g','h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
